(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{257:function(t,s,n){t.exports=n.p+"assets/img/pydata1.090db071.png"},258:function(t,s,n){t.exports=n.p+"assets/img/pydata2.d789b3b3.png"},259:function(t,s,n){t.exports=n.p+"assets/img/pydata7.b418ef05.png"},260:function(t,s,n){t.exports=n.p+"assets/img/pydata4.9a9808bf.png"},261:function(t,s,n){t.exports=n.p+"assets/img/pydata3.545bdae5.jpg"},262:function(t,s,n){t.exports=n.p+"assets/img/pydata5.021cff1f.png"},263:function(t,s,n){t.exports=n.p+"assets/img/pydata6.434d91cb.png"},337:function(t,s,n){"use strict";n.r(s);var a=n(28),e=Object(a.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"集中趋势"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#集中趋势"}},[t._v("#")]),t._v(" 集中趋势")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#集中趋势"}},[t._v("集中趋势")]),a("ul",[a("li",[a("a",{attrs:{href:"#均值"}},[t._v("均值")])]),a("li",[a("a",{attrs:{href:"#中位数"}},[t._v("中位数")])]),a("li",[a("a",{attrs:{href:"#众数"}},[t._v("众数")])]),a("li",[a("a",{attrs:{href:"#分位数"}},[t._v("分位数")])])]),a("ul",[a("li",[a("a",{attrs:{href:"#数据分布"}},[t._v("数据分布")]),a("ul",[a("li",[a("a",{attrs:{href:"#偏态系数与峰态系数"}},[t._v("偏态系数与峰态系数")])])])]),a("li",[a("a",{attrs:{href:"#抽样理论"}},[t._v("抽样理论")])])]),a("ul",[a("li",[a("a",{attrs:{href:"#数据分类"}},[t._v("数据分类")])]),a("li",[a("a",{attrs:{href:"#单属性分析"}},[t._v("单属性分析")]),a("ul",[a("li",[a("a",{attrs:{href:"#异常值分析"}},[t._v("异常值分析")]),a("ul",[a("li",[a("a",{attrs:{href:"#异常值分析与分布分析code"}},[t._v("异常值分析与分布分析code")])]),a("li",[a("a",{attrs:{href:"#四分位相关去异常值"}},[t._v("四分位相关去异常值")])])])]),a("li",[a("a",{attrs:{href:"#结构分析"}},[t._v("结构分析")])]),a("li",[a("a",{attrs:{href:"#对比分析"}},[t._v("对比分析")]),a("ul",[a("li",[a("a",{attrs:{href:"#自定义"}},[t._v("自定义")])]),a("li",[a("a",{attrs:{href:"#python检验是否为正太分布"}},[t._v("python检验是否为正太分布")])])])])])])])])])]),t._v("\n数据聚拢在哪"),a("p"),t._v(" "),a("h4",{attrs:{id:"均值"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#均值"}},[t._v("#")]),t._v(" 均值")]),t._v(" "),a("p",[t._v("一般指平均数。\n一般用在分布均匀的连续值")]),t._v(" "),a("h4",{attrs:{id:"中位数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#中位数"}},[t._v("#")]),t._v(" 中位数")]),t._v(" "),a("p",[t._v("中位数（Median）又称中值，是按顺序排列的一组数据中居于中间位置的数")]),t._v(" "),a("p",[t._v("一般用在 存在异常值，有些特别大，有些特别小的情况，用中位数来衡量ta的集中趋势")]),t._v(" "),a("h4",{attrs:{id:"众数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#众数"}},[t._v("#")]),t._v(" 众数")]),t._v(" "),a("p",[t._v("众数（Mode）是指在统计分布上具有明显集中趋势点的数值，代表数据的一般水平。 也是一组数据中出现次数最多的数值，有时众数在一组数中有好几个。")]),t._v(" "),a("blockquote",[a("p",[t._v("1，2，2，3，3，4的众数是2和3。\n1，2，3，3，4的众数是3\n1，2，3，4，5没有众数。")])]),t._v(" "),a("p",[t._v("一般众数用在离散值的衡量")]),t._v(" "),a("h4",{attrs:{id:"分位数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分位数"}},[t._v("#")]),t._v(" 分位数")]),t._v(" "),a("p",[t._v("分位数（Quantile），亦称分位点，是指将一个随机变量的概率分布范围分为几个等份的数值点，常用的有中位数（即二分位数）、四分位数、百分位数等。")]),t._v(" "),a("p",[t._v("最常用的是四分位,n是个数\nq1的位置 = (n+1)*0.25"),a("br"),t._v("\nq2的位置 = (n+1)*0.5"),a("br"),t._v("\nq3的位置 = (n+1)*0.75")]),t._v(" "),a("hr"),t._v(" "),a("p",[a("img",{attrs:{src:n(257),alt:""}}),t._v(" "),a("img",{attrs:{src:n(258),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"数据分布"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据分布"}},[t._v("#")]),t._v(" 数据分布")]),t._v(" "),a("p",[t._v("标准正态分布又称为u分布，是以0为均数、以1为标准差的正态分布，记为N（0，1）。\n"),a("img",{attrs:{src:n(259),alt:""}})]),t._v(" "),a("h4",{attrs:{id:"偏态系数与峰态系数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#偏态系数与峰态系数"}},[t._v("#")]),t._v(" 偏态系数与峰态系数")]),t._v(" "),a("p",[t._v("偏态，数据平均值偏离平均值的程度\n"),a("img",{attrs:{src:n(260),alt:""}})]),t._v(" "),a("h5",{attrs:{id:"上式值若为正，为正偏，反之为负偏"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#上式值若为正，为正偏，反之为负偏"}},[t._v("#")]),t._v(" 上式值若为正，为正偏，反之为负偏")]),t._v(" "),a("p",[a("img",{attrs:{src:n(261),alt:""}})]),t._v(" "),a("p",[t._v("峰度（peakedness;kurtosis）又称峰态系数。表征概率密度分布曲线在平均值处峰值高低的特征数。直观看来，峰度反映了峰部的尖度。样本的峰度是和正态分布相比较而言统计量，如果峰度大于三，峰的形状比较尖，比正态分布峰要陡峭。反之亦然。")]),t._v(" "),a("h3",{attrs:{id:"抽样理论"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#抽样理论"}},[t._v("#")]),t._v(" 抽样理论")]),t._v(" "),a("p",[t._v("分 重复抽样 和 非重复抽样\n抽样方式：随机抽样，等差距抽样，分类分别抽样")]),t._v(" "),a("p",[a("img",{attrs:{src:n(262),alt:""}}),t._v(" "),a("img",{attrs:{src:n(263),alt:""}})]),t._v(" "),a("hr"),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# res = df.head(10)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(res)")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(type(df)) ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# # <class 'pandas.core.frame.DataFrame'>")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(df["satisfaction_level"])')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0        0.38")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1        0.80")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2        0.11")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3        0.72")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4        0.37")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#          ... ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14997    0.11")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14998    0.37")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14999     NaN")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15000     NaN")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15001    0.70")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(type(df["satisfaction_level"]))')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <class 'pandas.core.series.Series'>")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 求均值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.mean())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level         0.612839")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation           67.373732")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project             3.802693")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours    201.041728")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company         3.498067")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident              0.144581")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                       0.238235")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years      0.021264")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(type(df.mean()))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <class 'pandas.core.series.Series'>")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#求某个系列的均值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(df["satisfaction_level"].mean())')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.6128393333333333")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中位数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.median())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level         0.64")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation            0.72")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project             4.00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours    200.00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company         3.00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident              0.00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                       0.00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years      0.00")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## 4分之一分位数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(df["satisfaction_level"].quantile(0.25))')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.44")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 众数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.mode())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    satisfaction_level  last_evaluation  ...  department  salary       ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0                 0.1             0.55  ...       sales     low       ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1                 NaN              NaN  ...         NaN     NaN ")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 离中趋势")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标准差   标准差是方差的算术平方根")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.std())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level          0.248623")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation          8164.407524")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project              1.232733")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours      49.941815")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company          1.460053")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident               0.351689")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                        0.426018")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years       0.144267")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方差var")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.var())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level       6.181359e-02")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation          6.665755e+07")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project           1.519630e+00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours    2.494185e+03")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company       2.131754e+00")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident            1.236854e-01")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                     1.814911e-01")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years    2.081307e-02")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(df["satisfaction_level"].var())')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.061813585758606134")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 求和")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df['satisfaction_level'].sum())")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 偏态系数skew")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.skew())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level        -0.476438     # 说明satisfaction_level平均值偏小，大部分的值，大于平均值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation          122.482652")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project             0.337774")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours      0.053225")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company         1.853530")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident              2.021481")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                       1.229057")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years      6.637677")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 峰度系数kurt   ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df.kurt())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# satisfaction_level          -0.670696   # 与正态分布作比较的， 负数，说明比正太分布还平缓")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# last_evaluation          15001.999987")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number_project              -0.495810")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# average_monthly_hours       -1.135016")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# time_spend_company           4.774353")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Work_accident                2.086664")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# left                        -0.489485")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# promotion_last_5years       42.064357")]),t._v("\n\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成一个正太分布")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标准正态分布又称为u分布，是以0为均数、以1为标准差的正态分布，记为N（0，1）。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scipy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" ss\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ss.norm")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# ss.norm.stats(moments="mvsk") # m均值 v方差  s偏态系数  k峰态系数')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pdf   #输入横坐标，返回纵坐标")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(ss.norn.pdf(0.0))")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ppf   #输入概率（0-1之间）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(ss.norm.ppf(0.9))  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 累计值：从负无穷到输入值")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cdf  从负无穷到输入值的累计概率   ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(ss.norm.cdf(1))   # 从负无穷到正一倍标准差的概率")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("norm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" ss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("norm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 从正2倍标准差到负两倍标准差的概率")]),t._v("\n\n\n\n")])])]),a("h2",{attrs:{id:"数据分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据分类"}},[t._v("#")]),t._v(" 数据分类")]),t._v(" "),a("ul",[a("li",[t._v("定类（类别）：根据事务离散/无差别属性进行的分类")]),t._v(" "),a("li",[t._v("定序（顺序）：可以界定数据的大小，但不能测定差值")]),t._v(" "),a("li",[t._v("定距（间隔）：可以界定数据大小的同时，可测定差值，但无绝对零点")]),t._v(" "),a("li",[t._v("定比（比率）：可以界定数据大小，可测定差值，有绝对零点")])]),t._v(" "),a("h2",{attrs:{id:"单属性分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#单属性分析"}},[t._v("#")]),t._v(" 单属性分析")]),t._v(" "),a("ul",[a("li",[t._v("异常值分析：离散异常值，连续异常值，常识异常值")]),t._v(" "),a("li",[t._v("对比分析：绝对数与相对数，时间、空间、理论维度比较")]),t._v(" "),a("li",[t._v("结构分析：各组成部分的分布规律")]),t._v(" "),a("li",[t._v("分布分析：数据分布频率的显式分析")])]),t._v(" "),a("h3",{attrs:{id:"异常值分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#异常值分析"}},[t._v("#")]),t._v(" 异常值分析")]),t._v(" "),a("h4",{attrs:{id:"异常值分析与分布分析code"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#异常值分析与分布分析code"}},[t._v("#")]),t._v(" 异常值分析与分布分析code")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 异常值分析")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 数据里有没有null")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# isnull() 方法")]),t._v("\nsl_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'satisfaction_level'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.isnull())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0        False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1        False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2        False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3        False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4        False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#          ...  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14997    False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14998    False")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14999     True")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15000     True")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15001    False")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查看有几条异常值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sl_s[sl_s.isnull()]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s[sl_s.isnull()])")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14999   NaN")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15000   NaN")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查看具体某项的值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( df[df['satisfaction_level'].isnull()]  )")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#        satisfaction_level  last_evaluation  ...  department  salary   ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 14999                 NaN             0.52  ...     support     low   ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15000                 NaN        999999.00  ...        sale     low  ")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 丢弃异常数据")]),t._v("\nsl_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sl_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df) 这里对sl_s的操作，不会直接影响df")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 除了丢弃数据，还有另一种方法就是填充数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sl_s = sl_s.fillna()")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里我选择丢弃数据吧")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 平均值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.mean())  ")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中位数median")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.median())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 下四分位数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.quantile(q=0.25))")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标准差")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.std())")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最大值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.max())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最小值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.min())")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 偏度skew")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( sl_s.skew() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -0.47643761717258093  负数，负偏，说明均数比较小，大部分数比均数大")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 峰度kurt")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( sl_s.kurt() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -0.6706959323886252 负数，说明，相对于标准正态分布来说，这个分布比较平缓")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ---------------")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 引入numpy，可以获取到 satisfaction_level  的离散化的分布")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(sl_s.values)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [0.38 0.8  0.11 ... 0.11 0.37 0.7 ]")]),t._v("\nres1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("histogram"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sl_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("bins"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#np.arange(起始，end，间隔多少)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(res1)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (array([ 195, 1214,  532,  974, 1668, 2146, 1973, 2074, 2220, 2004],  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#       dtype=int64), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 解读")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 195  -----  0.0到0.1之间一共有195个数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1214 -----  0.1到0.2之间一共由1214个")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ......")]),t._v("\n\n")])])]),a("h4",{attrs:{id:"四分位相关去异常值"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四分位相关去异常值"}},[t._v("#")]),t._v(" 四分位相关去异常值")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 异常值分析")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 数据里有没有null")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# isnull() 方法")]),t._v("\nle_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'last_evaluation'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先判断是否有空值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( le_s[le_s.isnull()] )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Series([], Name: last_evaluation, dtype: float64)  说明都有非空值")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 均值mean")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( le_s.mean() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 67.37373216904412    从数据表上粗略看，一般都是0-1之间的值，但这里60+感觉有点不对劲，哪里不对劲呢？")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标准差std")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s.std())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 8164.407523745649")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中位数median")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s.median())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.72")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s.max())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s.min())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 999999.0")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.36")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 偏度skew    （几何上均值的位置与中间的关系？）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( le_s.skew() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 122.48265175204614   正偏，说明均值比大多数值都要大")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 峰度kurt")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( le_s.kurt() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15001.999986807796   说明相对标准正太分布，该分布很陡")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查看大于某值的item")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( le_s[le_s>1] )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 15000    999999.0")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去掉异常值的方法1，low的方法")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取小于1的所有项")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# le_s = le_s[le_s<=1]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s)")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去掉异常值的方法2，推荐")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 理论")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 异常值的定义：")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 四分位间距=上四分位数-下四分位数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 上四分位数+1.5到3倍的间距，可以确定一个上界")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 下四分位数-1.5到3倍的间距，可以确定一个下界")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 上下界所确定的间距，可认为“正常值”")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 上下界之外的，可认为是“异常值”")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 下四分位数quantile")]),t._v("\nq_low "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" le_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 上四分位")]),t._v("\nq_high "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" le_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.75")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 四分位间距")]),t._v("\nq_interval "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" q_high "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" q_low\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(q_interval)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#0.30999999999999994")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 开始筛选")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置倍数")]),t._v("\nk "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),t._v("\nle_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" le_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("le_s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("q_high"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("k"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("q_interval"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("le_s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("q_low"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("k"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("q_interval"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 同时满足两个条件")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(le_s)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# len(le_s)")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 直方图")]),t._v("\nhis "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("histogram"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("le_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("bins "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("his"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (array([   0,    0,    0,  179, 1390, 3396, 2234, 2062, 2752, 2988],")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#       dtype=int64), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 解读")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0到0.1之间0个")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.1到0.2之间0个")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.2到0.3之间0个")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.3到0.4之间179个")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\n")])])]),a("h3",{attrs:{id:"结构分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#结构分析"}},[t._v("#")]),t._v(" 结构分析")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnp_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number_project'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 静态结构分析")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(np_s.mean())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(np_s.std())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(np_s.median)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# np_s.skew()")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# np_s.kurt()")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用np.histogram直方图去解释这个数据好像不是很合适")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 且number_project的值都在2-7之间的整数，离散型")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可以用出现的次数做研究")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( np_s.value_counts() )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4    4365")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3    4055")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5    2761")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2    2391")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6    1174")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 7     256")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 出现比例")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( np_s.value_counts(normalize = True) )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4    0.290961")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3    0.270297")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5    0.184042")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2    0.159379")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6    0.078256")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 7    0.017064")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 排序")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" np_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value_counts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("normalize "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2    0.159379")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3    0.270297")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4    0.290961")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5    0.184042")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6    0.078256")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 7    0.017064")]),t._v("\n")])])]),a("h5",{attrs:{id:"区间值分布"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#区间值分布"}},[t._v("#")]),t._v(" 区间值分布")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\namh_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'average_monthly_hours'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 均值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.mean())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标准差")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.std())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.max())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.min())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 偏度")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.skew())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 峰度")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s.kurt())")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去除异常值")]),t._v("\namh_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.75")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.75")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.75")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("quantile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(amh_s)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分布")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( np.histogram(amh_s.values,bins = 10) )   # 分10份")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (array([ 367, 1240, 2736, 1722, 1628, 1712, 1906, 2240, 1127,  324],  ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#       dtype=int64), array([ 96. , 117.4, 138.8, 160.2, 181.6, 203. , 224.4, 245.8, 267.2,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#        288.6, 310. ]))")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print( np.histogram(amh_s.values,bins = np.arange(amh_s.min(),amh_s.max()+10,10)) )")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (array([ 168,  171,  147,  807, 1153, 1234, 1075,  824,  818,  758,  751,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         738,  856,  824,  987, 1002, 1045,  935,  299,  193,  131,   86],")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#       dtype=int64), array([ 96, 106, 116, 126, 136, 146, 156, 166, 176, 186, 196, 206, 216,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#        226, 236, 246, 256, 266, 276, 286, 296, 306, 316], dtype=int64))")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 值次数，也可以 值区间 次数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("  amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value_counts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bins"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("amh_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 未加sort_index()的结果")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (146.0, 156.0]     1277")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (136.0, 146.0]     1159")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (256.0, 266.0]     1063")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (236.0, 246.0]     1006")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (156.0, 166.0]      995")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (246.0, 256.0]      987")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (126.0, 136.0]      886")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (216.0, 226.0]      873")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (266.0, 276.0]      860")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (166.0, 176.0]      832")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (226.0, 236.0]      814")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (176.0, 186.0]      813")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (186.0, 196.0]      761")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (196.0, 206.0]      755")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (206.0, 216.0]      731")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (276.0, 286.0]      319")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (95.999, 106.0]     187")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (286.0, 296.0]      164")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (116.0, 126.0]      162")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (106.0, 116.0]      162")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (296.0, 306.0]      128")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (306.0, 316.0]       68")]),t._v("\n")])])]),a("h5",{attrs:{id:"清楚异常值"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#清楚异常值"}},[t._v("#")]),t._v(" 清楚异常值")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ns_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'salary'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(s_s)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(s_s.value_counts())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# low       7318")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# medium    6446")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# high      1237")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# nme          1")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 清除异常值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" s_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("where"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'nme'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nd_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'department'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 频次")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(d_s.value_counts())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sales          4140")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# technical      2720")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# support        2230")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# IT             1227")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# product_mng     902")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# marketing       858")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# RandD           787")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# accounting      767")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# hr              739")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# management      630")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sale              2")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 频率")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(d_s.value_counts(normalize = True).sort_index())")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# IT             0.081789")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# RandD          0.052460")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# accounting     0.051127")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# hr             0.049260")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# management     0.041994")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# marketing      0.057192")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# product_mng    0.060125")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sale           0.000133")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sales          0.275963")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# support        0.148647")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# technical      0.181309")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去掉异常值")]),t._v("\nd_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" d_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("where"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sale"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value_counts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("normalize "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"对比分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#对比分析"}},[t._v("#")]),t._v(" 对比分析")]),t._v(" "),a("p",[t._v("得先剔除异常值")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去掉空值")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("how"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 多个筛选")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"last_evaluation"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"salary"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nme"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sale"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# axis表示删除行还是列，0为删除行")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# how   any表示这一行只要有一个异常数据就删除该行，["any","all"]  all是所有的都是空值的时候就删除')]),t._v("\n\n")])])]),a("h4",{attrs:{id:"自定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#自定义"}},[t._v("#")]),t._v(" 自定义")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/data/HR.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 去掉空值")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("how"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 多个筛选")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"last_evaluation"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"salary"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nme"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sale"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(df)")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 按部门分类")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分类后使用聚合操作，这里用均数")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# print(df.groupby("department").mean(),sep="\\n")')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#   df = df[df["last_evaluation"]<=1][df["salary"]!="nme"][df["department"]!="sale"]')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#              satisfaction_level  last_evaluation  number_project  average_monthly_hours  time_spend_company  Work_accident      left  promotion_last_5years")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# department")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# IT                     0.618142         0.716830        3.816626             202.215974            3.468623       0.133659  0.222494               0.002445")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# RandD                  0.619822         0.712122        3.853875             200.800508            3.367217       0.170267  0.153748               0.034307")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# accounting             0.582151         0.717718        3.825293             201.162973            3.522816       0.125163  0.265971               0.018253")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# hr                     0.598809         0.708850        3.654939             198.684709            3.355886       0.120433  0.290934               0.020298")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# management             0.621349         0.724000        3.860317             201.249206            4.303175       0.163492  0.144444               0.109524")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# marketing              0.618601         0.715886        3.687646             199.385781            3.569930       0.160839  0.236597               0.050117")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# product_mng            0.619634         0.714756        3.807095             199.965632            3.475610       0.146341  0.219512               0.000000")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sales                  0.614447         0.709717        3.776329             200.911353            3.534058       0.141787  0.244928               0.024155")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# support                0.618300         0.723109        3.803948             200.758188            3.393001       0.154778  0.248991               0.008973")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# technical              0.607897         0.721099        3.877941             202.497426            3.411397       0.140074  0.256250               0.010294")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 切片操作")]),t._v("\nres1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"last_evaluation"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupby"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [:,["last_evaluation","department"]]  行全部，列要["last_evaluation","department"]')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(res1)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#   df = df[df["last_evaluation"]<=1][df["salary"]!="nme"][df["department"]!="sale"]')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#              last_evaluation")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# department")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# IT                  0.716830")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# RandD               0.712122")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# accounting          0.717718")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# hr                  0.708850")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# management          0.724000")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# marketing           0.715886")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# product_mng         0.714756")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sales               0.709717")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# support             0.723109")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# technical           0.721099")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# loc、iloc提取行数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# :表示所有，[]里边为先行后列  .groupby("department").mean()')]),t._v("\nres2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"last_evaluation"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupby"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(res2)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 自定义")]),t._v("\nres3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"time_spend_company"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupby"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"department"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h4",{attrs:{id:"python检验是否为正太分布"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python检验是否为正太分布"}},[t._v("#")]),t._v(" python检验是否为正太分布")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scipy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" ss\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 随机生成一个符合标准正太分布的20个数")]),t._v("\nnorm_dist "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("norm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rvs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("norm_dist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("33")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如何检测是否是正太分布呢")]),t._v("\nres1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normaltest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# NormaltestResult(statistic=0.9547603432197074, pvalue=0.6204066234691221)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果显著性水平是0.05的话 pvalue  p值大于0.05则表示符合正太分布")])])])])])}),[],!1,null,null,null);s.default=e.exports}}]);