(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{310:function(t,s,n){t.exports=n.p+"assets/img/jsjy9.2ccf5cba.png"},311:function(t,s,n){t.exports=n.p+"assets/img/jsjy11.c04bfe3d.jpg"},312:function(t,s,n){t.exports=n.p+"assets/img/jsjy13.801c933e.jpg"},361:function(t,s,n){"use strict";n.r(s);var a=n(28),p=Object(a.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"独立双样本t检验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#独立双样本t检验"}},[t._v("#")]),t._v(" 独立双样本t检验")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#独立双样本t检验"}},[t._v("独立双样本t检验")]),a("ul",[a("li",[a("a",{attrs:{href:"#独立双样本t检验-与-单样本t检验有什么区别"}},[t._v("独立双样本T检验 与 单样本t检验有什么区别")])]),a("li",[a("a",{attrs:{href:"#标准误差的计算"}},[t._v("标准误差的计算")])]),a("li",[a("a",{attrs:{href:"#独立双样本t检验效应量的计算"}},[t._v("独立双样本T检验效应量的计算")])]),a("li",[a("a",{attrs:{href:"#独立双样本t检验code"}},[t._v("独立双样本T检验code")])])])])])]),a("p"),t._v(" "),a("p",[t._v("这是两款键盘布局不一样的手机(A版本，B版本)，你作为公司的产品经理，想在正式发布产品之前知道，哪个键盘布局对用户体验更好呢？")]),t._v(" "),a("p",[t._v("首先，我们需要设置目标，用来衡量各个版本的优劣，如果是电商网站，目标可以是点击率，注册率，页面停留时间等。")]),t._v(" "),a("p",[t._v("在这个键盘布局案例里，如果一个键盘布局对用户打字时拼错产生的影响较小，那么这个布局是符合用户体验习惯的。所以我们将目标定为用户打字时拼错字产生的影响。")]),t._v(" "),a("p",[t._v("有了目标以后，下一步就是采集数据。在这一部分，用户会随机分配到不同版本中，通过他们的交互行为会被直接检测，并收集起来作为以后分析的重要数据。")]),t._v(" "),a("p",[t._v("我们随机抽取实验者，将实验者分成2组，每组25人，A组使用键盘布局A，B组使用键盘布局B。让他们在30秒内打出标准的20个单词文字消息，然后记录打错字的数量。")]),t._v(" "),a("p",[t._v("我们将数据记录在Excel中，A列是使用键盘布局A打错字的数量，B列是使用键盘布局B打错字的数量。")]),t._v(" "),a("p",[t._v("现在我们开始A/B测试")]),t._v(" "),a("p",[a("img",{attrs:{src:n(310),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"独立双样本t检验-与-单样本t检验有什么区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#独立双样本t检验-与-单样本t检验有什么区别"}},[t._v("#")]),t._v(" 独立双样本T检验 与 单样本t检验有什么区别")]),t._v(" "),a("ul",[a("li",[t._v("误差的计算不一样")]),t._v(" "),a("li",[t._v("python函数不一样")]),t._v(" "),a("li",[t._v("得到自由度的方式不一样，单样本 和 相关样本检验  直接从数据得到，独立双样本从计算中得到")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#独立双样本t检验")]),t._v("\nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("st"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ttest_ind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        usevar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unequal'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#单样本t检验")]),t._v("\nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p_two "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ttest_1samp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataSer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("pop_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#相关样本检验")]),t._v("\nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p_two "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ttest_rel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'一致'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'不一致'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"标准误差的计算"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#标准误差的计算"}},[t._v("#")]),t._v(" 标准误差的计算")]),t._v(" "),a("p",[a("em",[t._v("独立样本T检验的标准误差计算")])]),t._v(" "),a("ul",[a("li",[t._v("s1:样本1的标准差")]),t._v(" "),a("li",[t._v("s2:样本2的标准差")]),t._v(" "),a("li",[t._v("n1样本1的数量，n2类似")])]),t._v(" "),a("p",[a("img",{attrs:{src:n(311),alt:""}})]),t._v(" "),a("p",[t._v("code")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("se"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("a_n "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("b_n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"独立双样本t检验效应量的计算"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#独立双样本t检验效应量的计算"}},[t._v("#")]),t._v(" 独立双样本T检验效应量的计算")]),t._v(" "),a("p",[t._v("s:标准差\n"),a("img",{attrs:{src:n(312),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"独立双样本t检验code"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#独立双样本t检验code"}},[t._v("#")]),t._v(" 独立双样本T检验code")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#导入包")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#文件路径")]),t._v("\nfileNameStr"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./键盘AB测试.xlsx'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#读取Ecxcel数据，统一先按照字符串读入，之后转换")]),t._v("\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_excel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fileNameStr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'object'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# data = xls.parse('Sheet1',dtype='object')")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#查看每一列的数据类型")]),t._v("\ndata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtypes\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#描述统计信息")]),t._v("\ndata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("describe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#字符串转换为数值（浮点型）")]),t._v("\ndata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'int'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("astype"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'int'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'转换后的数据类型：\\n'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtypes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#样本平均值")]),t._v("\na_mean"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nb_mean"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A版本平均值='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("a_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'单位：打错字数量'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B版本平均值='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'单位：打错字数量'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n这里要区别：数据集的标准差，和样本标准差\n数据集的标准差公式除以的是n，样本标准差公式除以的是n-1。\n样本标准差，用途是用样本标准差估计出总体标准差\npandas计算的标准差，默认除以的是n-1，也就是计算出的是样本标准差\npandas标准差官网地址：https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.std.html\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#样本标准差")]),t._v("\na_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nb_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A版本样本大小25，样本标准差='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("a_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'单位：打错字数量'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B版本样本大小25，样本标准差='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'单位：打错字数量'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 二、推论统计分析")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 推论统计分析报告中包括：假设检验，置信区间，效应量")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 问题是什么？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 零假设和备选假设")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 要研究的问题是：哪个键盘布局对用户体验更好呢？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据这个问题我提出来下面两个互为相反的假设。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 零假设：A版本和B版本没有差别，也就是A版本平均值=B版本平均值。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 零假设总是表述为研究没有改变，没有效果，不起作用等，这里就是不满足标准。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 备选假设：A版本和B版本有差别，也就是A版本平均值 不等于 B版本平均值。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检验类型")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检验类型有很多种，因为这里有2组样本，是不同的人，所以选择双独立样本检验。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检验类型参考资料：")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# http://support.minitab.com/zh-cn/minitab/17/topic-library/basic-statistics-and-graphs/hypothesis-tests/tests-of-means/types-of-t-tests/")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 抽样分布类型")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 我们还要判断抽样分布是哪种？因为抽样分布的类型，决定了后面计算p值的不同。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在我们这个AB测试案例中，样本大小是25（小于30），属于小样本。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那小样本的抽样分布是否满足t分布呢？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为t分布还要求总体分布近似正态分布，但是总体分布我们是不知道的，我们可以通过样本数据集的分布来推断总体分布。")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n直方图能够粗略估计数据密度，如果想给数据一个更精确的拟合曲线（专业术语叫：核密度估计kernel density estimate (KDE)），\nSeaborn 可以很方便的画出直方图和拟合曲线。\n查看数据集分布官网教程地址：https://seaborn.pydata.org/tutorial/distributions.html\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n需要先在navigator中安装绘图包seaborn，\n\n如果还不知道如何安装包，可以看第1关的教程：https://www.zhihu.com/question/58033789/answer/254673663\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" seaborn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sns\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#查看数据集分布")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A版本数据集分布'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B版本数据集分布'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 通过观察上面数据集分布图，两个样本数据集都近似正态分布，满足t分布的使用条件，所以抽样分布是t分布")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检验方向")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 单尾检验（左尾，右尾），还是双尾检验？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为备选假设是A版本和B版本有差别，也就是A版本平均值 不等于 B版本平均值，所以我们使用双尾检验。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 总结")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 综合以上分析，本次假设检验是双独立样本t检验，双尾检验。")]),t._v("\n\n\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.证据是什么？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在零假设成立前提下，得到样本平均值的概率p是多少？")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 独立双样本t检验，计算标准误差和自由度的公式想要深入了解的可以看这里：")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  https://en.wikipedia.org/wiki/Student%27s_t-test#Independent_two-sample_t-test")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nScipy的双独立样本t检验不能返回自由度，对于后面计算置信区间不方便。所以我们使用另一个统计包（statsmodels）\n\n需要先在navigator中安装统计包（statsmodels），\n如果还不知道如何安装包，可以看第1关的教程：https://www.zhihu.com/question/58033789/answer/254673663\n\n双独立（independent）样本t检验（ttest_ind）\nstatsmodels.stats.weightstats.ttest_ind\n官网使用文档http://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ttest_ind.html\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" statsmodels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weightstats "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" st\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nttest_ind：独立双样本t检验，\nusevar='unequal'两个总体方差不一样\n返回的第1个值t是假设检验计算出的（t值），\n第2个p_two是双尾检验的p值\n第3个df是独立双样本的自由度\n'''")]),t._v("\nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("st"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ttest_ind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        usevar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unequal'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#自由度一般只保留整数部分")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'p_two='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p_two"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("',df='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 判断标准是什么？")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#判断标准（显著水平）使用alpha=5%")]),t._v("\nalpha"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.05")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 做出结论")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n在课程中《章节33：独立双样本检验第4步：做出结论》有误，修正为下面最新的代码和对应文档《课程错误更正.doc》：\n双尾判断条件：\np_two（双尾检验的p值） < 判断标准（显著水平）alpha 时，\n拒绝零假设，有统计显著，也就是有显著差异\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#做出结论")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p_two"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" alpha"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'拒绝零假设，有统计显著，也就是接受备选假设'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'备选假设：A版本和B版本有差异'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'接受零假设，没有统计显著'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'零假设：A版本和B版本没有差异'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 独立双样本t(45)=-4.05 , p=.00019 (α=5%),双尾检验.(这里的t(45)，里面的45是前面计算出的t分布的自由度df）")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 统计上存在显著差异，拒绝零假设，从而验证A版本和B版本存在显著差异。")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5.置信区间")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 图片里是APA格式的置信区间：平均值的置信区间，95% CI=(a,b)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在报告告置信区间时，提供了这样几个信息：")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1）开头会说是哪种类型的置信区间 例如在单样本检验中是单个平均值的置信区间，但是在我们后面要讲到的相关样本检验是两个平均值之间差异的置信区间。 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在这个案例里，我们是单个平均值的置信区间")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2）置信水平和区间的上下限。")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置信水平（简写为CI），括号里写上下限。这里是955的置信水平")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n1）置信水平对应的t值（t_ci）\n查t表格可以得到，95%的置信水平，自由度是n-1对应的t值\n2）计算上下限,\n置信区间上限a=样本平均值 - t_ci ×标准误差\n置信区间下限b=样本平均值 - t_ci ×标准误差\n'''")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n95%的置信水平，自由度df对应的t值，可以查找t表格获取，\n也可以通过这个工具获取：https://www.graphpad.com/quickcalcs/statratio1/（利用这个工具获取t值，需要注意输入的概率值是1-95%=0.05）\n注意：课程中这里对应的下面t_ci值有误，以下面的值为准\n'''")]),t._v("\nt_ci"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0141")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#样本大小n")]),t._v("\na_n "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\nb_n "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nnumpy.square 平方\nnumpy.sqrt开方\n标准误差计算公式：\nhttps://en.wikipedia.org/wiki/Student%27s_t-test#Independent_two-sample_t-test\n'''")]),t._v("\nse"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("a_n "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("b_n "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n对于双独立样本检验\n置信区间的样本平均值=A版本平均值 - B版本平均值\n'''")]),t._v("\nsample_mean"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("a_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" b_mean\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#置信区间上限")]),t._v("\na"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sample_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" t_ci "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" se\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#置信区间下限")]),t._v("\nb"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sample_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" t_ci "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" se\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 两个平均值差异的置信区间，95置信水平 CI=[-2.762316,-2.677684]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置信区间是-2.76,-2.68,平均下来，使用A键盘的错误数量要比B键盘的要少大约3到2个")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 6.效应量")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 为什么要给出效应量？")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在判断某个调查研究的结果，是否有意义或者重要时，要考虑的另一项指标是效应量。效应量太小，意味着处理即使达到了显著水平，也缺乏实用价值。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所以，在假设检验中，我们给出了是否具有统计显著性，也要给出效应量，一起来判断研究结果是否有意义。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 效应量报告格式：d=x.xx ，R2=.xx")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n效应量：差异指标Cohen's d\n这里的标准差，因为是双独立样本，需要用合并标准差（pooled standard deviations）代替\n'''")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#合并标准差")]),t._v("\nsp"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b_n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("square"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("b_n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#效应量Cohen's d")]),t._v("\nd"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" b_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" sp\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d='")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("d"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 三、数据分析报告")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1、描述统计分析")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# A版本打错字数量 平均是5.08个，标准差是2.06个")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# B版本打错字数量 平均是7.8个，标准差是2.65个")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2、推论统计分析 1）假设检验 独立双样本t(45)=-4.05 , p=.00019 (α=5%) , 双尾检验")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 拒绝零假设，统计显著。")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2）置信区间 两个平均值差值的置信区间， 95%置信水平 CI=-2.76,-2.68")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3）效应量 d= - 1.32，效果显著")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=p.exports}}]);